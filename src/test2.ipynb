{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "601617b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:174: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n"
     ]
    },
    {
     "ename": "ArrowTypeError",
     "evalue": "('Did not pass numpy.dtype object', 'Conversion failed for column None with type int64')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e4e510a1f171>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0mtop10_industries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./cleaned_df.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/geopandas/geodataframe.py\u001b[0m in \u001b[0;36mto_parquet\u001b[0;34m(self, path, index, compression, **kwargs)\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_to_parquet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m         \u001b[0m_to_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/geopandas/io/arrow.py\u001b[0m in \u001b[0;36m_to_parquet\u001b[0;34m(df, path, index, compression, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m     )\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_geopandas_to_arrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0mparquet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/geopandas/io/arrow.py\u001b[0m in \u001b[0;36m_geopandas_to_arrow\u001b[0;34m(df, index)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_wkb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;31m# Store geopandas specific file-level metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyarrow/table.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyarrow/pandas_compat.py\u001b[0m in \u001b[0;36mdataframe_to_arrays\u001b[0;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns_to_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_can_definitely_zero_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m                     \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyarrow/pandas_compat.py\u001b[0m in \u001b[0;36mconvert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    563\u001b[0m             e.args += (\"Conversion failed for column {!s} with type {!s}\"\n\u001b[1;32m    564\u001b[0m                        .format(col.name, col.dtype),)\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfield_nullable\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnull_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             raise ValueError(\"Field {} was non-nullable but pandas column \"\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyarrow/pandas_compat.py\u001b[0m in \u001b[0;36mconvert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m         except (pa.ArrowInvalid,\n\u001b[1;32m    561\u001b[0m                 \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArrowNotImplementedError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._ndarray_to_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowTypeError\u001b[0m: ('Did not pass numpy.dtype object', 'Conversion failed for column None with type int64')"
     ]
    }
   ],
   "source": [
    "# Source: https://github.com/prestinomills/aqueduct/blob/Know_Your_Community_Pipelines/civis/geohub/ActiveBusinessBlockgroupAggregation/Active_Business_Finalized_Script.py\n",
    "# %load active_business_script.py\n",
    "\"\"\"\n",
    "Created on Wed May  1 08:51:03 2019\n",
    "@author: myrfid041\n",
    "\"\"\"\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import esri_credentials\n",
    "\n",
    "from sodapy import Socrata\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.features.summarize_data import join_features\n",
    "from IPython.display import display\n",
    "from arcgis.features import FeatureLayer\n",
    "from arcgis.features import FeatureLayerCollection\n",
    "\n",
    "lahub_user = os.environ[\"LAHUB_ACC_USERNAME\"]\n",
    "lahub_pass = os.environ[\"LAHUB_ACC_PASSWORD\"]\n",
    "\n",
    "\n",
    "#---Setting the Outputs\n",
    "OUTPUT_FILE = \"./Listing_of_Active_Businesses.csv\"\n",
    "output_layer_name = '067a9242fbef4afeb1ca0744952e5724'\n",
    "\n",
    "max_record_count = 250_000\n",
    "\n",
    "#---Pulling Active Business Data\n",
    "#client = Socrata(\"data.lacity.org\", None)\n",
    "#abiz = pd.DataFrame(client.get('ngkp-kqkn', limit=10000000))\n",
    "abiz = pd.read_pickle(\"../data/abiz.p\")\n",
    "\n",
    "\n",
    "#---Pull NAIC Industry Table\n",
    "n_table=(\n",
    "    'https://raw.githubusercontent.com/CityofLosAngeles/civis-gcp-transition/{}/'\n",
    "    'data/naics_industry_table.csv'\n",
    ")\n",
    "naics_table=pd.read_csv(n_table.format(\"active-business\"))\n",
    "\n",
    "\n",
    "\n",
    "def dataprep(df,naics_table):\n",
    "    # Grab location info\n",
    "    df = (df.dropna(subset=['location_1', 'naics'])\n",
    "        .assign(\n",
    "            location_2 = df.location_1.astype(str).str[34:-2]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df = df.assign(\n",
    "        longitude = df.location_2.str.split(\",\", expand=True)[0].astype(float),\n",
    "        latitude = df.location_2.str.split(\",\", expand=True)[1].astype(float),\n",
    "        naics_sector = df.naics.str[:2].astype(str),\n",
    "    ).dropna(subset=[\"longitude\", \"latitude\"])\n",
    "\n",
    "    # Merge in NAICS sector\n",
    "    df2 = pd.merge(df, \n",
    "                   naics_table.assign(\n",
    "                       naics_sector = naics_table.naics_sector.astype(str)\n",
    "                   ), \n",
    "            how = 'inner', on = 'naics_sector', validate = 'm:1'\n",
    "            )\n",
    "\n",
    "    # Create geometry column\n",
    "    gdf = gpd.GeoDataFrame(df2.dropna(subset=['longitude', 'latitude']), \n",
    "        geometry = gpd.points_from_xy(df2.longitude, df2.latitude),\n",
    "                                      crs = \"EPSG:4326\"\n",
    "    ).to_crs(\"EPSG:2229\") # Change to CA State Plane\n",
    "\n",
    "    # Import block groups\n",
    "    block_group_file=(\n",
    "        'https://raw.githubusercontent.com/CityofLosAngeles/civis-gcp-transition/{}/'\n",
    "        'data/LACounty_Blockgroup.geojson'\n",
    "    )\n",
    "    block = gpd.read_file(block_group_file.format(\"active-business\"))\n",
    "\n",
    "    # Aggregate\n",
    "    sjoin=gpd.sjoin(gdf, block, how='inner', op='intersects')\n",
    "    \n",
    "    sjoin = sjoin.assign(\n",
    "        GEOID10 = sjoin.GEOID10.astype(str).apply(lambda x: '{0:0>12}'.format(x))\n",
    "    )\n",
    "\n",
    "    sjoin2=(sjoin.pivot_table(index='GEOID10', \n",
    "                    values='business_name',\n",
    "                    columns=['naics_industry'], \n",
    "                    aggfunc=len)\n",
    "        .reset_index()\n",
    "        .fillna(0)\n",
    "        .rename_axis(None, axis=\"columns\")\n",
    "    )\n",
    "    \n",
    "    # Merge geometry back in, since we lose the block group's polygon geometry when we aggregate\n",
    "    sjoin3 = pd.merge(block, sjoin2, \n",
    "                      on = \"GEOID10\", how = \"inner\", validate = \"1:1\")\n",
    "    \n",
    "    return sjoin3\n",
    "\n",
    "\n",
    "def top10(df):\n",
    "    '''\n",
    "    Find the top 10 predominant industries in entire county\n",
    "    Exclude 2 categories\n",
    "    Return a list (used to update feature layer item property)\n",
    "    '''\n",
    "    \n",
    "    # Exclude these cols because we can't use idxmax on them\n",
    "    exclude_cols = ['CTBG10', 'CT10', 'AreaSqMil', 'LABEL', 'FIP10', 'FIP10RV',\n",
    "       'CDP_NAME', 'CITYNAME', 'COMMNAME', 'Shape_STAr', 'Shape_STLe',\n",
    "       'geometry',]\n",
    "    \n",
    "    county_aggregate = (\n",
    "        pd.DataFrame(df.drop(columns = exclude_cols)\n",
    "                     .set_index(\"GEOID10\")\n",
    "                     .idxmax(axis=1))\n",
    "        .reset_index()\n",
    "        .rename(columns = {0: \"predominant_industry\"})\n",
    "    )\n",
    "    \n",
    "    # Get a list, descending order\n",
    "    predominant_industries = (county_aggregate.predominant_industry.value_counts()\n",
    "                              .index\n",
    "                              .to_list()\n",
    "                             )\n",
    "    \n",
    "    # Exclude these categories, then grab top 10\n",
    "    exclude_me = ['Professional, Scientific, and Technical Services', \n",
    "              'Other Services (except Public Administration)']\n",
    "    for i in exclude_me:\n",
    "        predominant_industries.remove(i)\n",
    "    \n",
    "    top10_industries = predominant_industries[0:10]\n",
    "    \n",
    "    return top10_industries\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "ESRI stores the column names slightly differently (subject to 10 char limits)\n",
    "Use dict to map and rename (key-value pair)\n",
    "Key: dataframe's existing column name\n",
    "Value: ESRI column name\n",
    "'''\n",
    "layer_rename_columns_dict = {\n",
    "    'Accommodation and Food Services': 'Accommodation_and_Food_Services',\n",
    "    'Administrative and Support and Waste Management and Remediation Services': 'Administrative_and_Support_and_',\n",
    "    'Agriculture, Forestry, Fishing and Hunting': 'Agriculture__Forestry__Fishing_',\n",
    "    'Arts, Entertainment, and Recreation': 'Arts__Entertainment__and_Recrea',\n",
    "    'Construction': 'Construction',\n",
    "    'Educational Services': 'Educational_Services',\n",
    "    'Finance and Insurance': 'Finance_and_Insurance',\n",
    "    'Health Care and Social Assistance': 'Health_Care_and_Social_Assistan',\n",
    "    'Information': 'Information',\n",
    "    'Manufacturing': 'Manufacturing',\n",
    "    'Medical Marijuana Collective': 'Medical_Marijuana_Collective',\n",
    "    'Mining': 'Mining',\n",
    "    'Not Classified': 'Not_Classified',\n",
    "    'Other Services (except Public Administration)': 'Other_Services__except_Public_A',\n",
    "    'Professional, Scientific, and Technical Services': 'Professional__Scientific__and_T',\n",
    "    'Real Estate Rental and Leasing': 'Real_Estate_Rental_and_Leasing',\n",
    "    'Retail Trade': 'Retail_Trade',\n",
    "    'Transportation and Warehousing': 'Transportation_and_Warehousing',\n",
    "    'Utilities': 'Utilities',\n",
    "    'Wholesale Trade': 'Wholesale_Trade'                                               \n",
    "}\n",
    "\n",
    "\n",
    "df=dataprep(abiz,naics_table)\n",
    "top10_industries = top10(df)\n",
    "\n",
    "df.to_parquet(\"./cleaned_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b44625c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = layer_rename_columns_dict)\n",
    "for c in layer_rename_columns_dict.values():\n",
    "    df[c] = df[c].fillna(0).astype(int)\n",
    "    \n",
    "df.to_pickle(\"./cleaned_df.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d99ecf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a6b364badfb748aaa6771eb77a48f2ff\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"./cleaned_df.p\")\n",
    "\n",
    "lahub_user = esri_credentials.tiffany_user\n",
    "lahub_pass = esri_credentials.tiffany_pw\n",
    "output_layer_name = c_shapefile\n",
    "\n",
    "print(output_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0fc6669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path name: ./upload_me.zip\n",
      "Dirname (1st element of path): ./upload_me\n",
      "Shapefile name: upload_me.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile component parts folder: ./upload_me/upload_me.shp\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Make zipped shapefile (used for AGOL web app)\n",
    "def make_zipped_shapefile(df, path):\n",
    "    # Grab first element of path (can input filename.zip or filename)\n",
    "    dirname = os.path.splitext(path)[0]\n",
    "    print(f'Path name: {path}')\n",
    "    print(f'Dirname (1st element of path): {dirname}')\n",
    "    # Make sure there's no folder with the same name\n",
    "    shutil.rmtree(dirname, ignore_errors = True)\n",
    "    # Make folder\n",
    "    os.mkdir(dirname)\n",
    "    shapefile_name = f'{os.path.basename(dirname)}.shp'\n",
    "    print(f'Shapefile name: {shapefile_name}')\n",
    "    # Export shapefile into its own folder with the same name \n",
    "    df.to_file(driver = 'ESRI Shapefile', filename = f'{dirname}/{shapefile_name}')\n",
    "    print(f'Shapefile component parts folder: {dirname}/{shapefile_name}')\n",
    "    # Zip it up\n",
    "    shutil.make_archive(dirname, 'zip', dirname)\n",
    "    # Remove the unzipped folder\n",
    "    shutil.rmtree(dirname, ignore_errors = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "make_zipped_shapefile(\n",
    "    gpd.GeoDataFrame(df, geometry=df.geometry.to_crs(\"EPSG:4326\")), \n",
    "    \"./upload_me.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fac34ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geohub_updates(x,user,pas, feature_layer_id, \n",
    "        top10_industries, column_renaming_dict, OUTPUT_FILE):\n",
    "    gis = GIS('https://lahub.maps.arcgis.com',  username=user, password=pas)\n",
    "    '''\n",
    "    #feature_layer_id = '067a9242fbef4afeb1ca0744952e5724' # Preston's layer\n",
    "    actbus=gis.content.search(feature_layer_id)\n",
    "    ActiveBusinesses_item = actbus[0]\n",
    "    ActiveBusinesses_flayer = ActiveBusinesses_item.layers[0]\n",
    "    ActiveBusinesses_fset = ActiveBusinesses_flayer.query() #querying without any conditions returns all the features\n",
    "    # Possibly not all the block groups are mapped\n",
    "    # Select the block groups that are existing in the map (inner merge), and save those to CSV\n",
    "    '''\n",
    "    flayer = gis.content.get(feature_layer_id)\n",
    "    ActiveBusinesses_flayer = flayer.layers[0].query()\n",
    "    flayer_collection = FeatureLayerCollection.fromitem(flayer)\n",
    "    \n",
    "    existing_table = ActiveBusinesses_flayer.sdf\n",
    "    display(existing_table.head(10))\n",
    "    print(existing_table.columns)\n",
    "    print(existing_table.dtypes)\n",
    "    updated_table = pd.merge(\n",
    "        #existing_table[[\"OBJECTID\", \"GEOID10\", \"SHAPE\"]], \n",
    "        existing_table[[\"ObjectId\", \"GEOID10\", \"SHAPE\"]].assign(\n",
    "            GEOID10 = existing_table.GEOID10.str.replace(\"A\", \"\")\n",
    "        ),\n",
    "        # Rename columns to match, drop columns not in layer\n",
    "        # ESRI renamed the geometry to be SHAPE...and it's stored slightly different than in geodataframe\n",
    "        (df.rename(columns = layer_rename_columns_dict)\n",
    "        .drop(columns = ['Shape_STAr','Shape_STLe'])\n",
    "        ), \n",
    "        on = \"GEOID10\", \n",
    "        how = \"inner\")\n",
    "\n",
    "    # Integers, not floats\n",
    "    integrify_me = list(layer_rename_columns_dict.values())\n",
    "\n",
    "    for c in integrify_me:\n",
    "        updated_table[c] = updated_table[c].astype(int)\n",
    "    \n",
    "    #ActiveBusinesses_flayer.sdf = updated_table\n",
    "    #print(\"updated table\")\n",
    "    return updated_table\n",
    "\n",
    "    '''\n",
    "    # Stage 2 files, one to check into GitHub (no geometry), one to use to back dashboard\n",
    "    #gpd.GeoDataFrame(updated_table).to_file(driver = \"GeoJSON\", filename = \"./upload_me.geojson\")\n",
    "    updated_table.to_csv('./upload_me.csv', index=False)\n",
    "    updated_table[[\"GEOID10\"] + integrify_me].to_csv(OUTPUT_FILE, index=False)\n",
    "        \n",
    "    # Overwrite table\n",
    "    flayer_collection.manager.overwrite(\"./upload_me.csv\")\n",
    "    flayer_collection.manager.update_definition({\"maxRecordCount\": max_record_count})\n",
    "    \n",
    "    os.remove(\"./upload_me.geojson\")\n",
    "    \n",
    "    text = \"\"\"\n",
    "    This layer is aggregating \n",
    "    <a href=\"https://data.lacity.org/A-Prosperous-City/Listing-of-Active-Businesses/6rrh-rzua\">\n",
    "    Listing of Active Businesses Data</a> \n",
    "    that have geospatial information associated. \n",
    "    The top 10 most frequent industries in block groups are:\n",
    "    {}\n",
    "    \"\"\"\n",
    "    x = ', '.join([str(elem) for elem in top10_industries]) \n",
    "    item_props = {'title' : 'Active Businesses Data by Block Group', 'description':text.format(x)}\n",
    "    # Use flayer.update or flayer_collection.update?\n",
    "    flayer_collection.update(item_properties=item_props)\n",
    "    print(\"updates made!\")\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c583c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = geohub_updates(df, lahub_user, lahub_pass, output_layer_name,  top10_industries,\n",
    "        layer_rename_columns_dict, OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287fece0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afea4a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
